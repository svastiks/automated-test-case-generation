from openai import OpenAI
import os

def generate_improved_test_cases_and_report(evosuite_file, openai_file, report_file, output_java_file, output_report_md):
    """
    Generates improved test cases based on the comparison report and the two sets of test cases,
    and generates a final report explaining the improvements in Markdown format.
    
    Args:
        evosuite_file (str): Path to the EVOSuite test cases file.
        openai_file (str): Path to the OpenAI test cases file.
        report_file (str): Path to the comparison report file.
        output_java_file (str): Path to the output .java file for improved test cases.
        output_report_md (str): Path to the output .md file for the final report.
    """
    # Initialize the OpenAI client
    client = OpenAI()

    # Read the EVOSuite test cases
    with open(evosuite_file, "r") as f:
        evosuite_test_cases = f.read()

    # Read the OpenAI test cases
    with open(openai_file, "r") as f:
        openai_test_cases = f.read()

    # Read the comparison report
    with open(report_file, "r") as f:
        comparison_report = f.read()

    # Define the input for generating improved test cases
    input_text_for_test_cases = f"""
    You are a software testing expert. Based on the following inputs, generate an improved set of JUnit test cases:
    
    EVOSuite Test Cases:
    {evosuite_test_cases}
    
    OpenAI Test Cases:
    {openai_test_cases}
    
    Comparison Report:
    {comparison_report}
    
    Combine the strengths of both sets of test cases, address any missing areas mentioned in the report, 
    and generate a final set of JUnit test cases in proper Java syntax.
    """

    # Call the OpenAI API to generate improved test cases
    response_test_cases = client.responses.create(
        model="gpt-4o",  # Use the appropriate model
        input=input_text_for_test_cases
    )

    # Extract the improved test cases
    improved_test_cases = response_test_cases.output_text.strip()

    # Write the improved test cases to the output .java file
    with open(output_java_file, "w") as f:
        f.write(improved_test_cases)

    print(f"Improved test cases written to {output_java_file}")

    # Define the input for generating the final report
    input_text_for_report = f"""
    Based on the two input files‚Äîone containing test cases generated by EVOSuite and the other containing test cases generated by a large language model (LLM)‚Äîanalyze both sets and generate a concise but detailed comparison report.

    The report should:

    Highlight specific improvements introduced by the LLM-generated test cases

    Include precise code examples that add value or enhance coverage

    Point out what is missing in the EVOSuite tests and how the LLM complements them

    Focus on readability, functional correctness, and assertion clarity

    üìê Formatting Instructions:
    Use Markdown formatting with clear section headings

    Use emoji icons to enhance clarity:

    ‚úÖ for strengths or improvements

    ‚ùå for shortcomings

    üß™ for LLM code examples

    üõ†Ô∏è for EVOSuite explanations

    Present code in proper Java code blocks using triple backticks. When we say code we mean example snipets of code, not the entire test case.
    Must have a good amount of code snipet examples. 5 code snipets for each approach i.e. EVOSuite vs LLM.

    Use a lot of emojis for clarity and engagement

    Use bullet points for comparisons and concise comments explaining each point

    Include a summary comparison table (feature-by-feature)

    End with a brief, well-structured conclusion

    ‚ö†Ô∏è Keep the report informative but not long. Avoid repetition. Prioritize specificity and structure over length.
    
    EVOSuite Test Cases:
    {evosuite_test_cases}
    
    OpenAI Test Cases:
    {openai_test_cases}
    
    Comparison Report:
    {comparison_report}

    Improved Test Cases:
    {improved_test_cases}
    """

    # Call the OpenAI API to generate the final report
    response_report = client.responses.create(
        model="gpt-4o",  # Use the appropriate model
        input=input_text_for_report
    )

    # Extract the final report
    final_report = response_report.output_text.strip()

    # Write the final report to a Markdown file
    with open(output_report_md, "w") as f:
        f.write(final_report)

    print(f"Final report written to {output_report_md}")


# Example usage
desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
evosuite_file = os.path.join(desktop_path, "evo_suite_test_cases.txt")  # EVOSuite test cases file
openai_file = os.path.join(desktop_path, "openai_test_cases.txt")  # OpenAI test cases file
report_file = os.path.join(desktop_path, "comparison_report.txt")  # Comparison report file
output_java_file = os.path.join(desktop_path, "Money_ESTest.java")  # Output .java file
output_report_md = os.path.join(desktop_path, "FinalReport.md")  # Output .md file for the final report

generate_improved_test_cases_and_report(evosuite_file, openai_file, report_file, output_java_file, output_report_md)
